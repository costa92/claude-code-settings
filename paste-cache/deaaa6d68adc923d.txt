./scripts/03_lora_train.sh
Loading pretrained model
Fetching 9 files: 100%|████████████████████████████| 9/9 [00:00<00:00, 256794.12it/s]
Download complete: : 0.00B [00:00, ?B/s]                       | 0/9 [00:00<?, ?it/s]
Loading datasets
Training
Trainable parameters: 0.131% (10.486M/8030.261M)
Starting training..., iters: 50
Calculating loss...: 0it [00:00, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/mlx_lm/__main__.py", line 30, in <module>
    submodule.main()
    ~~~~~~~~~~~~~~^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/mlx_lm/lora.py", line 362, in main
    run(types.SimpleNamespace(**args))
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/mlx_lm/lora.py", line 334, , training_callback)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/mlx_lm/lora.py", line 288, in train_model
    train(
    ~~~~~^
        model=model,
        ^^^^^^^^^^^^
    ...<4 lines>...
        training_callback=training_callback,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/mlx_lm/tuner/trainer.py", line 274, in train
    val_loss = evaluate(
        model=model,
    ...<5 lines>...
        iterate_batches=iterate_batches,
    )
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/mlx_lm/tuner/trainer.py", line 180, in evaluate
    for _, batch in tqdm(
                    ~~~~^
        zip(
        ^^^^
    ...<9 lines>...
        total=min(len(dataset) // batch_size, num_batches),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/mlx_lm/tuner/trainer.py", line 106, in iterate_batches
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Dataset must have at least batch_size=2 examples but only has 1.